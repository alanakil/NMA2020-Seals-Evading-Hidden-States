{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This code extracts data about 1) spike counts for each trial, separated into correct/incorrect contralateral, ipsilateral, and nogo 2) percent corrent choices for each session of behavior and 3) average time from stimulus presentation to auditory GO cue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to run this code, you need to have the behavioral data dictionaries previously loaded in\n",
    "## see 'loading_in_tar' and 'loading_in_npy' files in repo, limited code copied below:\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "vis_ctx = np.load(\"V1_spikes.npy\", allow_pickle=True)\n",
    "spikes_times = np.load('spikes_times.npy', allow_pickle=True)\n",
    "goCue_times = np.load(\"goCue_times.npy\", allow_pickle=True)\n",
    "response_choices = np.load('response_choices.npy', allow_pickle=True)\n",
    "feedback_types = np.load('feedback_types.npy', allow_pickle=True)\n",
    "stim_times = np.load('stim_times.npy', allow_pickle=True)\n",
    "vis_clusters = np.load('V1_clusters.npy', allow_pickle=True)\n",
    "vis_timestamps = np.load('V1_timestamps.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get trial types (contra/ipsi/nogo) for a given session\n",
    "## calculate percent correct for each session\n",
    "\n",
    "perc_corr = np.zeros(40)\n",
    "sessions = np.arange(1, 40)\n",
    "trial_type = {new_key: [] for new_key in sessions}\n",
    "\n",
    "contra_corr_clusters = []\n",
    "contra_corr_spiketimes = []\n",
    "contra_corr_starts = []\n",
    "contra_corr_ends = []\n",
    "\n",
    "contra_incorr_clusters = []\n",
    "contra_incorr_spiketimes = []\n",
    "contra_incorr_starts = []\n",
    "contra_incorr_ends = []\n",
    "\n",
    "ipsi_corr_clusters = []\n",
    "ipsi_corr_spiketimes = []\n",
    "ipsi_corr_starts = []\n",
    "ipsi_corr_ends = []\n",
    "\n",
    "ipsi_incorr_clusters = []\n",
    "ipsi_incorr_spiketimes = []\n",
    "ipsi_incorr_starts = []\n",
    "ipsi_incorr_ends = []\n",
    "\n",
    "nogo_clusters = []\n",
    "nogo_spiketimes = []\n",
    "nogo_starts = []\n",
    "nogo_ends = []\n",
    "\n",
    "contra_starts = []\n",
    "contra_sessions = []\n",
    "ipsi_starts = []\n",
    "ipsi_sessions = []\n",
    "beh_contra = []\n",
    "beh_ipsi = []\n",
    "\n",
    "for s in sessions:\n",
    "    print('session', s)\n",
    "    trials = len(goCue_times[s]) # nTrials\n",
    "    contra_Ctrials = np.zeros(trials) # tracking trials where correct response is contraleteral to probe\n",
    "    contra_Itrials = np.zeros(trials) # tracking trials where INcorrect response is contraleteral to probe\n",
    "    ipsi_Ctrials = np.zeros(trials) # tracking trials where correct response is ipsileteral to probe\n",
    "    ipsi_Itrials = np.zeros(trials) # tracking trials where correct response is ipsileteral to probe\n",
    "    nogo_trials = np.zeros(trials) # tracking NoGo trials\n",
    "    \n",
    "    for t in range(trials):\n",
    "        response = int(response_choices[s][t]) # -1 right, 0 nogo, 1 left\n",
    "        feedback = int(feedback_types[s][t]) # -1 incorrect, 1 correct\n",
    "        if response == 1 and feedback == 1:\n",
    "            contra_Ctrials[t] = 1\n",
    "            contra_starts.append(stim_times[s][t])\n",
    "            contra_sessions.append(s)\n",
    "            beh_contra.append(1)\n",
    "        elif response == 1 and feedback == -1:\n",
    "            contra_Itrials[t] = 1\n",
    "            beh_contra.append(0)\n",
    "            contra_starts.append(stim_times[s][t])\n",
    "            contra_sessions.append(s)\n",
    "        elif response == -1 and feedback == 1:\n",
    "            ipsi_Ctrials[t] = 1\n",
    "            beh_ipsi.append(1)\n",
    "            ipsi_starts.append(stim_times[s][t])\n",
    "            ipsi_sessions.append(s)\n",
    "        elif response == -1 and feedback == -1:\n",
    "            ipsi_Itrials[t] = 1\n",
    "            beh_ipsi.append(0)\n",
    "            ipsi_starts.append(stim_times[s][t])\n",
    "            ipsi_sessions.append(s)\n",
    "        elif response == 0:\n",
    "            nogo_trials[t] = 1\n",
    "    \n",
    "    pc = np.count_nonzero(feedback_types[s]==1)/(len(feedback_types[s]))\n",
    "    perc_corr[s] = pc\n",
    "    trial_type[s] = np.stack((contra_Ctrials, contra_Itrials, ipsi_Ctrials, ipsi_Itrials, nogo_trials), axis=0)\n",
    "    \n",
    "    ## now that we know which trials are which type, we need timestamps for each of those trials to get FR\n",
    "    time_window = []\n",
    "    \n",
    "    for t in range(trials):\n",
    "\n",
    "        lowerT = stim_times[s][t]\n",
    "        upperT = goCue_times[s][t]\n",
    "        this_trial_spikes = []\n",
    "        this_cluster = []\n",
    "        trial_start = []\n",
    "        trial_end = []\n",
    "        \n",
    "        for key,value in vis_timestamps.items():\n",
    "            if s == key:\n",
    "                all_stamps = np.arange(1, len(vis_timestamps[s]))\n",
    "                for i in all_stamps:\n",
    "                    if lowerT <= vis_timestamps[s][i] < upperT: \n",
    "                        this_trial_spikes.append(float(vis_timestamps[s][i]))\n",
    "                        this_cluster.append(int((vis_clusters[s][i])))\n",
    "                        trial_start.append(lowerT)\n",
    "                        trial_end.append(upperT)\n",
    "                        \n",
    "        time_window.append(upperT-lowerT)\n",
    "\n",
    "        if trial_type[s][0][t] == 1: ## if this contra trial was correct\n",
    "            contra_corr_spiketimes.extend(this_trial_spikes)\n",
    "            contra_corr_clusters.extend(this_cluster)\n",
    "            contra_corr_starts.extend(trial_start)\n",
    "            contra_corr_ends.extend(trial_end)\n",
    "\n",
    "        elif trial_type[s][1][t] == 1: ## if this contra trial was incorrect\n",
    "            contra_incorr_spiketimes.extend(this_trial_spikes)\n",
    "            contra_incorr_clusters.extend(this_cluster)\n",
    "            contra_incorr_starts.extend(trial_start)\n",
    "            contra_incorr_ends.extend(trial_end)\n",
    "\n",
    "        elif trial_type[s][2][t] == 1: ## if this ipsi trial was correct\n",
    "            ipsi_corr_spiketimes.extend(this_trial_spikes)\n",
    "            ipsi_corr_clusters.extend(this_cluster)\n",
    "            ipsi_corr_starts.extend(trial_start)\n",
    "            ipsi_corr_ends.extend(trial_end)\n",
    "\n",
    "        elif trial_type[s][3][t] == 1: ## if this ipsi trial was incorrect\n",
    "            ipsi_incorr_spiketimes.extend(this_trial_spikes)\n",
    "            ipsi_incorr_clusters.extend(this_cluster)\n",
    "            ipsi_incorr_starts.extend(trial_start)\n",
    "            ipsi_incorr_ends.extend(trial_end)\n",
    "\n",
    "        elif trial_type[s][4][t] == 1: ## if this was a nogo trial\n",
    "            nogo_spiketimes.extend(this_trial_spikes)\n",
    "            nogo_clusters.extend(this_cluster)\n",
    "            nogo_starts.extend(trial_start)\n",
    "            nogo_ends.extend(trial_end)\n",
    "            \n",
    "contralateral_behavior = np.vstack((np.squeeze(np.asarray(contra_starts)), np.asarray(contra_sessions), \n",
    "                              np.asarray(beh_contra)))\n",
    "\n",
    "ipsilateral_behavior = np.vstack((np.squeeze(np.asarray(ipsi_starts)), np.asarray(ipsi_sessions), \n",
    "                              np.asarray(beh_ipsi)))\n",
    "\n",
    "np.savetxt('contralateral_behavior.txt', contralateral_behavior)\n",
    "np.savetxt('ipsilateral_behavior.txt', ipsilateral_behavior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "contra_corr_dict = {'n_neuron':contra_corr_clusters, 'spiketimes':contra_corr_spiketimes, 'starts': contra_corr_starts, 'ends': contra_corr_ends}\n",
    "contra_incorr_dict = {'n_neuron':contra_incorr_clusters, 'spiketimes':contra_incorr_spiketimes, 'starts': contra_incorr_starts, 'ends': contra_incorr_ends}\n",
    "ipsi_corr_dict = {'n_neuron':ipsi_corr_clusters, 'spiketimes':ipsi_corr_spiketimes, 'starts': ipsi_corr_starts, 'ends': ipsi_corr_ends}\n",
    "ipsi_incorr_dict = {'n_neuron':ipsi_incorr_clusters, 'spiketimes':ipsi_incorr_spiketimes, 'starts': ipsi_incorr_starts, 'ends': ipsi_incorr_ends}\n",
    "nogo_dict = {'n_neuron':nogo_clusters, 'spiketimes':nogo_spiketimes, 'starts': nogo_starts, 'ends': nogo_ends}\n",
    "\n",
    "os.chdir('/Users/srbindas/Documents/GitHub/NMA2020-Seals-Evading-Hidden-States/npy files')\n",
    "\n",
    "file_to_write = open(\"contra_corr_dict.npy\", \"wb\")\n",
    "pickle.dump(contra_corr_dict, file_to_write)\n",
    "\n",
    "file_to_write = open(\"contra_incorr_dict.npy\", \"wb\")\n",
    "pickle.dump(contra_incorr_dict, file_to_write)\n",
    "\n",
    "file_to_write = open(\"ipsi_corr_dict.npy\", \"wb\")\n",
    "pickle.dump(ipsi_corr_dict, file_to_write)\n",
    "\n",
    "file_to_write = open(\"ipsi_incorr_dict.npy\", \"wb\")\n",
    "pickle.dump(ipsi_incorr_dict, file_to_write)\n",
    "\n",
    "file_to_write = open(\"nogo_dict.npy\", \"wb\")\n",
    "pickle.dump(nogo_dict, file_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR PCA\n",
    "nrows = len(contra_corr_dict['n_neuron'])+len(contra_incorr_dict['n_neuron'])\n",
    "for_pca = np.zeros((nrows, 4))\n",
    "for_pca[0:(len(contra_corr_dict['n_neuron'])), 0]=contra_corr_dict['n_neuron']\n",
    "for_pca[0:(len(contra_corr_dict['n_neuron'])), 1]=contra_corr_dict['spiketimes']\n",
    "for_pca[0:(len(contra_corr_dict['n_neuron'])), 2]=contra_corr_dict['starts']\n",
    "for_pca[0:(len(contra_corr_dict['n_neuron'])), 3]=contra_corr_dict['ends']\n",
    "for_pca[len(contra_corr_dict['n_neuron']):, 0]=contra_incorr_dict['n_neuron']\n",
    "for_pca[len(contra_corr_dict['n_neuron']):, 1]=contra_incorr_dict['spiketimes']\n",
    "for_pca[len(contra_corr_dict['n_neuron']):, 2]=contra_incorr_dict['starts']\n",
    "for_pca[len(contra_corr_dict['n_neuron']):, 3]=contra_incorr_dict['ends']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving to file\n",
    "np.savetxt('matrix_for_pca.txt', for_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FOR PCA - validation\n",
    "nrows = len(ipsi_corr_dict['n_neuron'])+len(ipsi_incorr_dict['n_neuron'])\n",
    "for_pca_IPS = np.zeros((nrows, 4))\n",
    "for_pca_IPS[0:(len(ipsi_corr_dict['n_neuron'])), 0]=ipsi_corr_dict['n_neuron']\n",
    "for_pca_IPS[0:(len(ipsi_corr_dict['n_neuron'])), 1]=ipsi_corr_dict['spiketimes']\n",
    "for_pca_IPS[0:(len(ipsi_corr_dict['n_neuron'])), 2]=ipsi_corr_dict['starts']\n",
    "for_pca_IPS[0:(len(ipsi_corr_dict['n_neuron'])), 3]=ipsi_corr_dict['ends']\n",
    "for_pca_IPS[len(ipsi_corr_dict['n_neuron']):, 0]=ipsi_incorr_dict['n_neuron']\n",
    "for_pca_IPS[len(ipsi_corr_dict['n_neuron']):, 1]=ipsi_incorr_dict['spiketimes']\n",
    "for_pca_IPS[len(ipsi_corr_dict['n_neuron']):, 2]=ipsi_incorr_dict['starts']\n",
    "for_pca_IPS[len(ipsi_corr_dict['n_neuron']):, 3]=ipsi_incorr_dict['ends']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving to file\n",
    "np.savetxt('ipsilateral_for_pca.txt', for_pca_IPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
